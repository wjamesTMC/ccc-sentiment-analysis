---
title: "CCC Sentiment Analysis"
date: "`r format(Sys.time(), '%d %B, %Y')`" 
output: "html_document"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, out.width='90%', comment=NA)
pagebreak <- function() {
  if(knitr::is_latex_output())
    return("\\newpage")
  else
    return('<div style="page-break-before: always;" />')
}
```

```{r File open and setup, include=FALSE}
# Import libraries
library(tidyverse)
library(tidyr)
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
library(ggthemes)
library(extrafont)
library(scales)
library(reshape2)
library(stringi)
library(stringr)
library(expss)
library(grid)
library(gridExtra)
library(lattice)
library(janitor)
library(rmarkdown)
library(kableExtra)
library(googlesheets)

#--------------------------------------------------------------------
#
# File open, cleanup, and set up for the analysis
#
#--------------------------------------------------------------------

#
# Download and open file
#

# Import and Open the data file / Establish the data set
data_filename <- "19 08 12-18.csv"
stats_period  <- substr(data_filename, start = 1, stop = 11)
dat <- read.csv(data_filename, stringsAsFactors = FALSE)

vocab_filename <- "0_Input_Vocabulary.csv"
comms          <- read.csv(vocab_filename, stringsAsFactors = FALSE)
pos_vocab      <- comms %>% filter(Tone == "Positive")
neg_vocab      <- comms %>% filter(Tone == "Negative")
neu_vocab      <- comms %>% filter(Tone == "Neutral")

#
# Clean data file to set vector names
#

dat <- rename(dat, replace = c("Clients_CCC__c" = "Client",
                               "Products_Topics_CCC__c" = "Topic"))
              
# Select the desired columns
dat <- dat %>% select(Id,Subject, Description, Client, Topic, Type)

# Remove lines with known not relevant strings
dat <- dat %>% filter(!str_detect(Description, 'Ignore this message'))
dat <- dat %>% filter(!str_detect(Description, 'out of the office'))
dat <- dat %>% filter(!str_detect(Description, 'for immediate release'))
dat <- dat %>% filter(!str_detect(Description, 'Kindle Personal Document Service'))
dat <- dat %>% filter(!str_detect(Description, 'connect on LinkedIn'))
dat <- dat %>% filter(!str_detect(Description, 'Please share this with your members'))
dat <- dat %>% filter(!str_detect(Description, 'Sent from my Samsung device'))
dat <- dat %>% filter(!str_detect(Description, 'This note is to confirm that the message'))
dat <- dat %>% filter(!str_detect(Description, 'Sent from my iPhone'))
dat <- dat %>% filter(!str_detect(Description, 'Longyear Museum'))
dat <- dat %>% filter(!str_detect(Description, 'View this email in your browser'))
dat <- dat %>% filter(!str_detect(Description, 'dataprotection+unsubscribe@csps.com'))
dat <- dat %>% filter(!str_detect(Description, 'Test Comment'))
dat <- dat %>% filter(!str_detect(Description, 'murdered'))

# Remove lines where Type is junk or misdirected or otherwise erroneous
dat <- dat %>% filter(Type != "Junk")
dat <- dat %>% filter(Type != "Duplicate")
dat <- dat %>% filter(Type != "Misdirected")
dat <- dat %>% filter(Type != "")
dat <- dat %>% filter(Type != "Out of Office")
dat <- dat %>% filter(Type != "No Answer")
dat <- dat %>% filter(Description != "")

Subj_list   <- unique(dat$Subject)
Client_list <- unique(dat$Client)
Topic_list  <- unique(dat$Topic)
Type_list   <- unique(dat$Type)

# Calc the number of comments (remove "NR" from the count)
num_descs <- sapply(dat, function(x)length(unique(x)))[3]
```

This report covers statistics for the period of `r stats_period`

**Summary Statistics After File Reduction**

The statistics below arre net of entries labeled "junk", "no answer" and similar categorizations appropriate for removing them from the analysis.

Unique IDs         : `r sapply(dat, function(x)length(unique(x)))[1]`  
Unique Subjects    : `r sapply(dat, function(x)length(unique(x)))[2]`  
Unique Descriptions: `r sapply(dat, function(x)length(unique(x)))[3]`  
Unique Clients     : `r sapply(dat, function(x)length(unique(x)))[4]`  
Unique Topics      : `r sapply(dat, function(x)length(unique(x)))[5]`  
Unique Categories  : `r sapply(dat, function(x)length(unique(x)))[6]`  

**Section 1 - Descriptions with More than Two Negative Words (1st 500 Words)**
 
```{r Particularly negative entries, echo=FALSE, comment=NA}
#--------------------------------------------------------------------
#
# Sentiment analysis - Identify descriptions with high negative rating
# 
#--------------------------------------------------------------------

# Set threshold for negative words
neg_limit <- 2

# What we want to do here is look through the cut-down data file, examine each
# description, count the number of negative words, and save off that particular
# entry so they can be written to a file for management to examine

# First build a data frame to hold the identified entries. Set the size to 
# equal the number of descriptions and later clip off unused rows
neg_desc_df <- data.frame(Desc_ID = num_descs, Desc_text = num_descs, Neg_words = num_descs)

# Loop to test each negative word against each description
neg_word_count <- 0
df_counter     <- 1

for(i in 1:num_descs) {
     
     # This line removeS punctuation in the description to leave just text
     dat$Desc[i] <- gsub("[[:punct:]]", "", dat$Desc[i])
     
     # Now remove all line breaks
     dat$Desc[i] <- gsub("[\r\n]", "", dat$Desc[i])
     
     for(j in 1:nrow(neg_vocab)) {
          
          # Look for instances where a negative word is found
          x <- str_detect(dat$Desc[i], neg_vocab$Term[j])
          
          # if we find an instance, count it
          if(x == TRUE) {
               neg_word_count = neg_word_count + 1
          }
     }
     if(neg_word_count > neg_limit) {
          neg_desc_df[df_counter, 1] <- dat$Id[i]
          neg_desc_df[df_counter, 2] <- dat$Desc[i]
          neg_desc_df[df_counter, 3] <- neg_word_count
          df_counter <- df_counter + 1
     }
     # Reset the neg word counter to 0
     neg_word_count <- 0
}

# Print out results
for(i in 1:nrow(neg_desc_df)) {
     cat("Number ", i, "of", nrow(neg_desc_df), "- ID:", neg_desc_df[i,1], " ", "Negative words:", neg_desc_df[i,3], "\n", "\n")
     cat(substr(neg_desc_df[i,2], start = 1, stop = 500), "\n", "\n")
}
```

**Section 2: Word Occurrence Summaries (Top 10's)**

**1 - Positive Words**

```{r Positive Word Summary, echo=FALSE, comment=NA}

#--------------------------------------------------------------------
#
# Sentiment analysis - Cumulative
#
#--------------------------------------------------------------------

#
# Positive vocabulary elements
#

# Build dataframe for positives
pos_df   <- data.frame(Word  = pos_vocab$Term,
                       Count = 1:nrow(pos_vocab),
                       Type  = "Pos")

# Loop to identify positive words in the comments field
pct <- 0
for(i in 1:nrow(pos_vocab)) {
  x <- str_detect(dat$Desc, pos_vocab$Term[i])
  pos_df[i, 2] <- length(x[x == TRUE])
  pct <- pct + length(x[x == TRUE])
}

# Remove words with zero counts
pos_df  <- pos_df %>% filter(Count != 0)

# Sort from high to low
pos_df <- arrange(pos_df, desc(Count), Word)

kable(pos_df[1:10, ]) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")

```

**2 - Negative Words**

```{r Negative Word Summar, echo=FALSE}
#
# Negative vocabulary elements
#

# Build dataframe for negatives
neg_df   <- data.frame(Word  = neg_vocab$Term,
                       Count = 1:nrow(neg_vocab),
                       Type  = "Neg")


# Loop to identify negative words in the comments field
nct <- 0
for(i in 1:nrow(neg_vocab)) {
  x <- str_detect(dat$Desc, neg_vocab$Term[i])
  neg_df[i, 2] <- length(x[x == TRUE])
  nct <- nct + length(x[x == TRUE])
}

# Remove words with zero counts
neg_df   <- neg_df %>% filter(Count != 0)

# Sort from high to low
neg_df <- arrange(neg_df, desc(Count), Word)

# Print out the top 10 words
kable(neg_df[1:10, ]) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

**3 - Neutral Words**

```{r Neutral Words Summary, echo=FALSE}
#
# Neutral vocabulary elements
#

# Build dataframe for neutral words
neu_df   <- data.frame(Word  = neu_vocab$Term,
                       Count = 1:nrow(neu_vocab),
                       Type  = "Neu")


# Loop to identify neutral words in the comments field
neu_ct <- 0
for(i in 1:nrow(neu_vocab)) {
  x <- str_detect(dat$Desc, neu_vocab$Term[i])
  neu_df[i, 2] <- length(x[x == TRUE])
  neu_ct <- neu_ct + length(x[x == TRUE])
}

# Remove words with zero counts
neu_df   <- neu_df %>% filter(Count != 0)

# Sort from high to low
neu_df <- arrange(neu_df, desc(Count), Word)

# Print out the top 10 words
kable(neu_df[1:10, ]) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

**Overall Summary**

```{r Summary Section, echo=FALSE, comment=NA}

# Create datafrane and append negatives and neutrals
cum_count_df <- pos_df
cum_count_df <- rbind(cum_count_df, neg_df)
cum_count_df <- rbind(cum_count_df, neu_df)

# Determine overall positive and negative indexes (pos / neg words / comments
pos_index <- sum(pos_df$Count) / num_descs
neg_index <- sum(neg_df$Count) / num_descs
neu_index <- sum(neu_df$Count) / num_descs

# Create a filename and write out the results
filename <- paste("0_Output_sentiment_analysis",".csv")
filename <- stri_replace_all_fixed(filename, " ", "")
write.csv(cum_count_df, file = filename)

cat(" Number of input lines           :", nrow(dat), "\n",
    "Number of descriptions          :", num_descs, "\n",
    "Ratio of descriptions to lines  :", num_descs / nrow(dat), "\n", "\n",
    "Number of positive words        :", pct, "\n",
    "Positive words to descs ratio   :", pos_index, "\n", "\n",
    "Number of negative words        :", nct, "\n",
    "Negative words to descs ratio   :", neg_index, "\n", "\n",
    "Number of neutral words         :", neu_ct, "\n",
    "Neutral words to descs ratio    :", neu_index, "\n")

```

`r pagebreak()`

**Appendix: All Word Occurrences and Counts**

**1 - Positives**

```{r TWO - Pos, echo=FALSE}

kable(pos_df) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

**2 - Negatives**

```{r TWO - Negatives, echo=FALSE}

kable(neg_df) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

**3 - Neutrals**

```{r TWO - Neutrals, echo=FALSE}

kable(neu_df) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

**End of Document**